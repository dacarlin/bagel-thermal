{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "\n",
    "data_set = pandas.read_csv( '../data_sets/experimental_data/thermo_paper_data_set.csv', index_col=0 )\n",
    "expression_data = data_set[ [ 'expression' ] ] \n",
    "\n",
    "df = pandas.read_csv( '/Users/alex/Documents/bagel-benchmark/data_sets/rosetta/enzyme_design_noncovalent.csv', sep='\\s+' )\n",
    "df.description = df.description.str.split( '_' ).str[1]\n",
    "df = df.groupby( 'description' ).apply( lambda x: x.sort_values( by='total_score' ).head( 10 ).mean() ) \n",
    "\n",
    "df = df.join( expression_data ).dropna() \n",
    "y = df.expression\n",
    "X = df.drop( 'expression', axis=1 ).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [13 14 17 19 23 32 35 37 41 45 50] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/bin/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.648 (+/-0.202) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.648 (+/-0.202) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.648 (+/-0.202) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.603 (+/-0.120) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.603 (+/-0.120) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.628 (+/-0.133) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.595 (+/-0.142) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.611 (+/-0.017) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.590 (+/-0.162) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.590 (+/-0.162) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.590 (+/-0.162) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.597 (+/-0.038) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.645 (+/-0.126) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.645 (+/-0.126) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.584 (+/-0.193) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.645 (+/-0.126) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.577 (+/-0.175) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.668 (+/-0.172) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.597 (+/-0.038) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.668 (+/-0.172) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.601 (+/-0.141) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.668 (+/-0.172) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.611 (+/-0.017) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.644 (+/-0.142) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.644 (+/-0.142) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.631 (+/-0.095) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.644 (+/-0.142) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.568 (+/-0.019) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.643 (+/-0.160) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.643 (+/-0.160) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.701 (+/-0.185) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.643 (+/-0.160) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.678 (+/-0.172) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.604 (+/-0.083) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.602 (+/-0.100) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.604 (+/-0.083) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.629 (+/-0.218) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.604 (+/-0.083) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.611 (+/-0.017) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.668 (+/-0.089) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.668 (+/-0.089) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.653 (+/-0.126) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.668 (+/-0.089) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.702 (+/-0.114) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.718 (+/-0.137) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.611 (+/-0.017) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.718 (+/-0.137) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.696 (+/-0.085) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.718 (+/-0.137) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.712 (+/-0.129) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.696 (+/-0.076) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.689 (+/-0.110) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.696 (+/-0.076) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.681 (+/-0.077) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.696 (+/-0.076) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.41      0.67      0.51        18\n",
      "        1.0       0.78      0.55      0.65        38\n",
      "\n",
      "avg / total       0.66      0.59      0.60        56\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.509 (+/-0.110) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.509 (+/-0.110) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.509 (+/-0.110) for {'kbest__k': 1, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.418 (+/-0.154) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.418 (+/-0.154) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.564 (+/-0.093) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.400 (+/-0.151) for {'kbest__k': 1, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.782 (+/-0.011) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.491 (+/-0.221) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.491 (+/-0.221) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.491 (+/-0.221) for {'kbest__k': 3, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.709 (+/-0.142) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.473 (+/-0.246) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.455 (+/-0.201) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.709 (+/-0.142) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.509 (+/-0.169) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.564 (+/-0.022) for {'kbest__k': 3, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.782 (+/-0.011) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.545 (+/-0.113) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.545 (+/-0.113) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.709 (+/-0.060) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.545 (+/-0.113) for {'kbest__k': 9, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.509 (+/-0.248) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.545 (+/-0.028) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.545 (+/-0.028) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.600 (+/-0.064) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.545 (+/-0.028) for {'kbest__k': 9, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.600 (+/-0.064) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.509 (+/-0.068) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.509 (+/-0.183) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.509 (+/-0.068) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.527 (+/-0.203) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.509 (+/-0.068) for {'kbest__k': 9, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.782 (+/-0.011) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.509 (+/-0.068) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.509 (+/-0.068) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.764 (+/-0.039) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.509 (+/-0.068) for {'kbest__k': 21, 'svm__C': 0.3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.600 (+/-0.143) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.582 (+/-0.046) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.782 (+/-0.011) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.582 (+/-0.046) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.582 (+/-0.046) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.582 (+/-0.046) for {'kbest__k': 21, 'svm__C': 3, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "0.564 (+/-0.022) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.001}\n",
      "0.582 (+/-0.116) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.001}\n",
      "0.564 (+/-0.093) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.0001}\n",
      "0.582 (+/-0.116) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.0001}\n",
      "0.600 (+/-0.231) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'rbf', 'svm__gamma': 0.01}\n",
      "0.582 (+/-0.116) for {'kbest__k': 21, 'svm__C': 30, 'svm__kernel': 'linear', 'svm__gamma': 0.01}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        18\n",
      "        1.0       0.68      1.00      0.81        38\n",
      "\n",
      "avg / total       0.46      0.68      0.55        56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets, pipeline , preprocessing, feature_selection\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "    { \n",
    "        'svm__kernel': ['rbf', 'linear'], \n",
    "        'svm__gamma': [ 1e-3, 1e-4, 1e-2 ],\n",
    "        'svm__C': [ 0.3, 3, 30 ], \n",
    "        'kbest__k': [ 1, 3, 9, 21, ], \n",
    "    },    \n",
    "]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    pln = pipeline.Pipeline([ \n",
    "        ( 'scaler', preprocessing.StandardScaler() ),\n",
    "        ( 'kbest', feature_selection.SelectKBest( feature_selection.f_classif ) ), \n",
    "        ( 'svm', SVC( class_weight='balanced' ) ), \n",
    "    ])\n",
    "    \n",
    "    clf = GridSearchCV(pln, tuned_parameters, cv=3,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1.0, 'gamma': 0.10000000000000001} with a score of 0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# Utility function to move the midpoint of a colormap to be around\n",
    "# the values of interest.\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "##############################################################################\n",
    "# Load and prepare data set\n",
    "#\n",
    "# dataset for grid search\n",
    "\n",
    "# Dataset for decision function visualization: we only keep the first two\n",
    "# features in X and sub-sample the dataset to keep only 2 classes and\n",
    "# make it a binary classification problem.\n",
    "\n",
    "X = X.as_matrix()\n",
    "y = y.ravel()\n",
    "\n",
    "X_2d = X[:, :2]\n",
    "X_2d = X_2d[y > 0]\n",
    "y_2d = y[y > 0]\n",
    "y_2d -= 1\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "##############################################################################\n",
    "# Train classifiers\n",
    "#\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(y, n_iter=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(class_weight='balanced'), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# # Now we need to fit a classifier for all parameters in the 2d version\n",
    "# # (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "# C_2d_range = [1e-2, 1, 1e2]\n",
    "# gamma_2d_range = [1e-1, 1, 1e1]\n",
    "# classifiers = []\n",
    "# for C in C_2d_range:\n",
    "#     for gamma in gamma_2d_range:\n",
    "#         clf = SVC(C=C, gamma=gamma)\n",
    "#         clf.fit(X_2d, y_2d)\n",
    "#         classifiers.append((C, gamma, clf))\n",
    "\n",
    "# ##############################################################################\n",
    "# # visualization\n",
    "# #\n",
    "# # draw visualization of parameter effects\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "# for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "#     # evaluate decision function in a grid\n",
    "#     Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     # visualize decision function for these parameters\n",
    "#     plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "#     plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "#               size='medium')\n",
    "\n",
    "#     # visualize parameter's effect on decision function\n",
    "#     plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "#     plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu_r)\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "#     plt.axis('tight')\n",
    "\n",
    "# plot the scores of the grid\n",
    "# grid_scores_ contains parameter settings and scores\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in grid.grid_scores_]\n",
    "scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "#\n",
    "# The score are encoded as colors with the hot colormap which varies from dark\n",
    "# red to bright yellow. As the most interesting scores are all located in the\n",
    "# 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "# as to make it easier to visualize the small variations of score values in the\n",
    "# interesting range while not brutally collapsing all the low score values to\n",
    "# the same color.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
